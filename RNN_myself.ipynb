{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h', 'i', 'l', 'o', 'e'}\n"
     ]
    }
   ],
   "source": [
    "#hihello를 RNN으로 구현하기\n",
    "input_data='hihello'\n",
    "char_list=set(input_data)\n",
    "print(char_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h': array([1., 0., 0., 0., 0.]), 'i': array([0., 1., 0., 0., 0.]), 'l': array([0., 0., 1., 0., 0.]), 'o': array([0., 0., 0., 1., 0.]), 'e': array([0., 0., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "vocabulary={}\n",
    "for _,i in enumerate(char_list):\n",
    "    result=np.zeros(len(char_list))\n",
    "    result[_]=1\n",
    "    vocabulary[i]=result\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "input_data_one_hot_coded=[]\n",
    "for i in input_data:\n",
    "    input_data_one_hot_coded.append(vocabulary[i])\n",
    "input_data_one_hot_coded=np.array(input_data_one_hot_coded)\n",
    "print(input_data_one_hot_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super().__init__()\n",
    "        self.i2h=nn.Linear(input_size,hidden_size)\n",
    "        self.h2h=nn.Linear(hidden_size,hidden_size)\n",
    "        self.h2o=nn.Linear(hidden_size,input_size) #input_size와 output size를 동일하게 하였다.\n",
    "        self.activation=nn.Tanh()\n",
    "    def forward(self,input_data,hidden_state):\n",
    "        z=(self.i2h.forward(input_data)+self.h2h.forward(hidden_state))\n",
    "        hidden=self.activation.forward(z)\n",
    "        predict=self.h2o(hidden)\n",
    "        return predict,hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.210399627685547\n",
      "10.217915534973145\n",
      "9.44580078125\n",
      "8.517879486083984\n",
      "7.378930568695068\n",
      "6.270646572113037\n",
      "5.27294397354126\n",
      "4.429452419281006\n",
      "3.7596383094787598\n",
      "3.2391421794891357\n",
      "2.838336706161499\n",
      "2.5160300731658936\n",
      "2.230282783508301\n",
      "1.9606225490570068\n",
      "1.7157304286956787\n",
      "1.5020077228546143\n",
      "1.3185632228851318\n",
      "1.1621192693710327\n",
      "1.029186487197876\n",
      "0.9162663817405701\n",
      "0.8199894428253174\n",
      "0.7374290227890015\n",
      "0.6661683320999146\n",
      "0.6042280793190002\n",
      "0.5499783158302307\n",
      "0.5020822286605835\n",
      "0.4594545066356659\n",
      "0.4212336838245392\n",
      "0.38675981760025024\n",
      "0.35555848479270935\n",
      "0.32731199264526367\n",
      "0.3018084764480591\n",
      "0.27888017892837524\n",
      "0.2583501935005188\n",
      "0.24001207947731018\n",
      "0.22363317012786865\n",
      "0.20897486805915833\n",
      "0.1958138644695282\n",
      "0.1839512139558792\n",
      "0.173217311501503\n",
      "0.16346777975559235\n",
      "0.1545809656381607\n",
      "0.14645427465438843\n",
      "0.13899999856948853\n",
      "0.13214311003684998\n",
      "0.12581783533096313\n",
      "0.11996909230947495\n",
      "0.11454824358224869\n",
      "0.10951308906078339\n",
      "0.10482583194971085\n",
      "0.10045395791530609\n",
      "0.09636886417865753\n",
      "0.09254499524831772\n",
      "0.08895930647850037\n",
      "0.08559189736843109\n",
      "0.08242439478635788\n",
      "0.07944153249263763\n",
      "0.07662750780582428\n",
      "0.0739697813987732\n",
      "0.071456678211689\n",
      "0.06907758116722107\n",
      "0.06682231277227402\n",
      "0.06468241661787033\n",
      "0.06264979392290115\n",
      "0.06071711704134941\n",
      "0.058878250420093536\n",
      "0.05712597444653511\n",
      "0.055454712361097336\n",
      "0.05386098474264145\n",
      "0.0523381382226944\n",
      "0.05088244751095772\n",
      "0.04949018359184265\n",
      "0.04815702885389328\n",
      "0.046880535781383514\n",
      "0.045656610280275345\n",
      "0.04448256269097328\n",
      "0.043355587869882584\n",
      "0.04227276146411896\n",
      "0.04123220965266228\n",
      "0.04023182392120361\n",
      "0.039268795400857925\n",
      "0.03834218531847\n",
      "0.037449173629283905\n",
      "0.03658871352672577\n",
      "0.03575915843248367\n",
      "0.0349588617682457\n",
      "0.03418618440628052\n",
      "0.03343994542956352\n",
      "0.03271956741809845\n",
      "0.03202339634299278\n",
      "0.0313497819006443\n",
      "0.03069814294576645\n",
      "0.030067894607782364\n",
      "0.029457619413733482\n",
      "0.028866847977042198\n",
      "0.0282943993806839\n",
      "0.02773933671414852\n",
      "0.027201417833566666\n",
      "0.026679828763008118\n",
      "0.026173731312155724\n"
     ]
    }
   ],
   "source": [
    "model=RNN(5,3)\n",
    "optimizer=torch.optim.Adam(model.parameters(),0.01)\n",
    "cost_list=[]\n",
    "for i in range(1000):\n",
    "    total_cost=0\n",
    "    hidden_state=torch.zeros(3)\n",
    "    optimizer.zero_grad()\n",
    "    for _,j in enumerate(input_data_one_hot_coded[:-1]):\n",
    "        x=torch.FloatTensor(input_data_one_hot_coded[_])\n",
    "        y=torch.LongTensor(input_data_one_hot_coded[_+1])\n",
    "        predict,hidden_state=model.forward(x,hidden_state)\n",
    "        cost=F.cross_entropy(predict.unsqueeze(0),y.argmax().unsqueeze(0))\n",
    "        total_cost+=cost\n",
    "    total_cost.backward()\n",
    "    optimizer.step()\n",
    "    cost_list.append(total_cost.item())\n",
    "    if i%100==0:\n",
    "        print(total_cost.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7437)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(torch.tensor([[1,0,0,0.]]),torch.tensor([1])) #2d 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hihello\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "output='h'\n",
    "hiden_state=torch.zeros(3)\n",
    "for _,j in enumerate(input_data_one_hot_coded[:-1]):\n",
    "    x=torch.FloatTensor(input_data_one_hot_coded[_])\n",
    "    predict,hidden_state=model.forward(x,hidden_state)\n",
    "    output+=list(char_list)[predict.argmax().item()]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN Basics\n",
    "input_size=5\n",
    "hidden_size=3\n",
    "rnn=nn.RNN(input_size,hidden_size)\n",
    "outputs,hidden_state=rnn.forward(torch.FloatTensor(input_data_one_hot_coded).unsqueeze(0)) #input data shape : (batch size, seq length, # of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1.]), array([0., 0., 1., 0., 0.]), array([0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0.]), array([1., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]]]\n",
      "(3, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "#batch size와 seq length는 automatically calculate 된다.\n",
    "input_data_2=['hihello','ihelloh','hellohi']\n",
    "input_data_2_one_hot_coded=[]\n",
    "for i in input_data_2:\n",
    "    result=[]\n",
    "    for j in i:\n",
    "        result.append(vocabulary[j])\n",
    "    input_data_2_one_hot_coded.append(result)\n",
    "input_data_2_one_hot_coded=np.array(input_data_2_one_hot_coded)\n",
    "print(input_data_2_one_hot_coded)\n",
    "print(input_data_2_one_hot_coded.shape) #3,7,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0313,  0.5725, -0.4446,  0.4473],\n",
      "         [-0.1808,  0.0325,  0.0327,  0.5436],\n",
      "         [-0.0313,  0.5725, -0.4446,  0.4473],\n",
      "         [-0.4741,  0.3437, -0.4145,  0.4427],\n",
      "         [-0.2642,  0.4076, -0.5945,  0.5804],\n",
      "         [-0.2642,  0.4076, -0.5945,  0.5804],\n",
      "         [-0.6864,  0.1600, -0.5862,  0.6096]],\n",
      "\n",
      "        [[-0.2404,  0.4622, -0.1179,  0.7261],\n",
      "         [-0.3406,  0.6117, -0.5382,  0.4739],\n",
      "         [-0.5210,  0.6783, -0.5315,  0.6566],\n",
      "         [-0.5056,  0.5430, -0.7265,  0.7268],\n",
      "         [-0.4431,  0.6907, -0.7472,  0.7375],\n",
      "         [-0.7804,  0.5212, -0.7415,  0.7575],\n",
      "         [-0.4321,  0.6643, -0.6957,  0.6057]],\n",
      "\n",
      "        [[-0.3734,  0.7248, -0.5593,  0.6248],\n",
      "         [-0.6075,  0.6266, -0.5813,  0.6924],\n",
      "         [-0.5495,  0.6578, -0.7441,  0.7974],\n",
      "         [-0.5429,  0.7011, -0.7826,  0.7818],\n",
      "         [-0.8139,  0.5919, -0.7688,  0.8199],\n",
      "         [-0.4661,  0.7459, -0.7154,  0.7132],\n",
      "         [-0.4067,  0.4533, -0.2654,  0.7773]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.3734,  0.7248, -0.5593,  0.6248],\n",
      "         [-0.6075,  0.6266, -0.5813,  0.6924],\n",
      "         [-0.5495,  0.6578, -0.7441,  0.7974],\n",
      "         [-0.5429,  0.7011, -0.7826,  0.7818],\n",
      "         [-0.8139,  0.5919, -0.7688,  0.8199],\n",
      "         [-0.4661,  0.7459, -0.7154,  0.7132],\n",
      "         [-0.4067,  0.4533, -0.2654,  0.7773]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_data_2_one_hot_coded=torch.FloatTensor(input_data_2_one_hot_coded)\n",
    "rnn=nn.RNN(5,4)\n",
    "outputs,hidden_state=rnn.forward(input_data_2_one_hot_coded)\n",
    "print(outputs) # 3, 7, 4\n",
    "print(hidden_state) #1,7,4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([array([1., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0.]), array([1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1.]), array([0., 0., 1., 0., 0.]), array([0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0.])])\n",
      " list([array([0., 1., 0., 0., 0.]), array([1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1.]), array([0., 0., 1., 0., 0.]), array([0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0.])])\n",
      " list([array([1., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0.]), array([1., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0.])])]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "#seq len을 다르게 한다면?\n",
    "#batch size와 seq length는 automatically calculate 된다.\n",
    "input_data_3=['hihello','ihello','hlohi']\n",
    "input_data_3_one_hot_coded=[]\n",
    "for i in input_data_3:\n",
    "    result=[]\n",
    "    for j in i:\n",
    "        result.append(vocabulary[j])\n",
    "    input_data_3_one_hot_coded.append(result)\n",
    "input_data_3_one_hot_coded=np.array(input_data_3_one_hot_coded)\n",
    "print(input_data_3_one_hot_coded)\n",
    "print(input_data_3_one_hot_coded.shape) #3,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-48ba5060daf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_data_3_one_hot_coded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data_3_one_hot_coded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data_3_one_hot_coded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 3, 7, 4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1,7,4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "input_data_3_one_hot_coded=torch.FloatTensor(input_data_3_one_hot_coded)\n",
    "rnn=nn.RNN(5,4)\n",
    "outputs,hidden_state=rnn.forward(input_data_3_one_hot_coded)\n",
    "print(outputs) # 3, 7, 4\n",
    "print(hidden_state) #1,7,4  #안되네..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
