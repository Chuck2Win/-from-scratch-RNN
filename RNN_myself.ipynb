{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h', 'i', 'l', 'o', 'e'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-41c52ce1f817>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mchar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mchar_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#hihello를 RNN으로 구현하기\n",
    "input_data='hihello'\n",
    "char_list=set(input_data)\n",
    "print(char_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h': array([1., 0., 0., 0., 0.]), 'i': array([0., 1., 0., 0., 0.]), 'l': array([0., 0., 1., 0., 0.]), 'o': array([0., 0., 0., 1., 0.]), 'e': array([0., 0., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "vocabulary={}\n",
    "for _,i in enumerate(char_list):\n",
    "    result=np.zeros(len(char_list))\n",
    "    result[_]=1\n",
    "    vocabulary[i]=result\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "input_data_one_hot_coded=[]\n",
    "for i in input_data:\n",
    "    input_data_one_hot_coded.append(vocabulary[i])\n",
    "input_data_one_hot_coded=np.array(input_data_one_hot_coded)\n",
    "print(input_data_one_hot_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super().__init__()\n",
    "        self.i2h=nn.Linear(input_size,hidden_size)\n",
    "        self.h2h=nn.Linear(hidden_size,hidden_size)\n",
    "        self.h2o=nn.Linear(hidden_size,input_size) #input_size와 output size를 동일하게 하였다.\n",
    "        self.activation=nn.Tanh()\n",
    "    def forward(self,input_data,hidden_state):\n",
    "        z=(self.i2h.forward(input_data)+self.h2h.forward(hidden_state))\n",
    "        hidden=self.activation.forward(z)\n",
    "        predict=self.h2o(hidden)\n",
    "        return predict,hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.210399627685547\n",
      "10.217915534973145\n",
      "9.44580078125\n",
      "8.517879486083984\n",
      "7.378930568695068\n",
      "6.270646572113037\n",
      "5.27294397354126\n",
      "4.429452419281006\n",
      "3.7596383094787598\n",
      "3.2391421794891357\n",
      "2.838336706161499\n",
      "2.5160300731658936\n",
      "2.230282783508301\n",
      "1.9606225490570068\n",
      "1.7157304286956787\n",
      "1.5020077228546143\n",
      "1.3185632228851318\n",
      "1.1621192693710327\n",
      "1.029186487197876\n",
      "0.9162663817405701\n",
      "0.8199894428253174\n",
      "0.7374290227890015\n",
      "0.6661683320999146\n",
      "0.6042280793190002\n",
      "0.5499783158302307\n",
      "0.5020822286605835\n",
      "0.4594545066356659\n",
      "0.4212336838245392\n",
      "0.38675981760025024\n",
      "0.35555848479270935\n",
      "0.32731199264526367\n",
      "0.3018084764480591\n",
      "0.27888017892837524\n",
      "0.2583501935005188\n",
      "0.24001207947731018\n",
      "0.22363317012786865\n",
      "0.20897486805915833\n",
      "0.1958138644695282\n",
      "0.1839512139558792\n",
      "0.173217311501503\n",
      "0.16346777975559235\n",
      "0.1545809656381607\n",
      "0.14645427465438843\n",
      "0.13899999856948853\n",
      "0.13214311003684998\n",
      "0.12581783533096313\n",
      "0.11996909230947495\n",
      "0.11454824358224869\n",
      "0.10951308906078339\n",
      "0.10482583194971085\n",
      "0.10045395791530609\n",
      "0.09636886417865753\n",
      "0.09254499524831772\n",
      "0.08895930647850037\n",
      "0.08559189736843109\n",
      "0.08242439478635788\n",
      "0.07944153249263763\n",
      "0.07662750780582428\n",
      "0.0739697813987732\n",
      "0.071456678211689\n",
      "0.06907758116722107\n",
      "0.06682231277227402\n",
      "0.06468241661787033\n",
      "0.06264979392290115\n",
      "0.06071711704134941\n",
      "0.058878250420093536\n",
      "0.05712597444653511\n",
      "0.055454712361097336\n",
      "0.05386098474264145\n",
      "0.0523381382226944\n",
      "0.05088244751095772\n",
      "0.04949018359184265\n",
      "0.04815702885389328\n",
      "0.046880535781383514\n",
      "0.045656610280275345\n",
      "0.04448256269097328\n",
      "0.043355587869882584\n",
      "0.04227276146411896\n",
      "0.04123220965266228\n",
      "0.04023182392120361\n",
      "0.039268795400857925\n",
      "0.03834218531847\n",
      "0.037449173629283905\n",
      "0.03658871352672577\n",
      "0.03575915843248367\n",
      "0.0349588617682457\n",
      "0.03418618440628052\n",
      "0.03343994542956352\n",
      "0.03271956741809845\n",
      "0.03202339634299278\n",
      "0.0313497819006443\n",
      "0.03069814294576645\n",
      "0.030067894607782364\n",
      "0.029457619413733482\n",
      "0.028866847977042198\n",
      "0.0282943993806839\n",
      "0.02773933671414852\n",
      "0.027201417833566666\n",
      "0.026679828763008118\n",
      "0.026173731312155724\n"
     ]
    }
   ],
   "source": [
    "model=RNN(5,3)\n",
    "optimizer=torch.optim.Adam(model.parameters(),0.01)\n",
    "cost_list=[]\n",
    "for i in range(1000):\n",
    "    total_cost=0\n",
    "    hidden_state=torch.zeros(3)\n",
    "    optimizer.zero_grad()\n",
    "    for _,j in enumerate(input_data_one_hot_coded[:-1]):\n",
    "        x=torch.FloatTensor(input_data_one_hot_coded[_])\n",
    "        y=torch.LongTensor(input_data_one_hot_coded[_+1])\n",
    "        predict,hidden_state=model.forward(x,hidden_state)\n",
    "        cost=F.cross_entropy(predict.unsqueeze(0),y.argmax().unsqueeze(0))\n",
    "        total_cost+=cost\n",
    "    total_cost.backward()\n",
    "    optimizer.step()\n",
    "    cost_list.append(total_cost.item())\n",
    "    if i%100==0:\n",
    "        print(total_cost.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7437)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(torch.tensor([[1,0,0,0.]]),torch.tensor([1])) #2d 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hihello\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "output='h'\n",
    "hiden_state=torch.zeros(3)\n",
    "for _,j in enumerate(input_data_one_hot_coded[:-1]):\n",
    "    x=torch.FloatTensor(input_data_one_hot_coded[_])\n",
    "    predict,hidden_state=model.forward(x,hidden_state)\n",
    "    output+=list(char_list)[predict.argmax().item()]\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
